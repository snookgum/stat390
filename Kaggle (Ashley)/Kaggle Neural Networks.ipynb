{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db6a833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 11:07:12.328494: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from keras.utils import set_random_seed\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import * \n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16fbc791",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "nan_cols = test.isna().sum()\n",
    "test1 = test.drop(nan_cols[nan_cols > 269].index.tolist(), axis = 1)\n",
    "train1 = train.drop(nan_cols[nan_cols > 269].index.tolist(), axis = 1)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# fit and transform the data\n",
    "test_imputed = pd.DataFrame(imputer.fit_transform(test1), columns=test1.columns)\n",
    "train_imputed = pd.DataFrame(imputer.fit_transform(train1), columns=train1.columns)\n",
    "\n",
    "corr_matrix = train_imputed.corr().abs()\n",
    "\n",
    "corr_y = train_imputed.corrwith(train_imputed['y'])\n",
    "train_imputed.drop(corr_y[corr_y.isna()].index.tolist(), axis = 1, inplace = True)\n",
    "test_imputed.drop(corr_y[corr_y.isna()].index.tolist(), axis = 1, inplace = True)\n",
    "\n",
    "# identify predictors that have correlation of > 0.85\n",
    "indices = np.where(np.triu(corr_matrix > 0.85, k=1))\n",
    "\n",
    "# print the pairs of columns that have a correlation > 0.85\n",
    "high_corr = []\n",
    "count = 0\n",
    "for idx in range(len(indices[0])):\n",
    "    col1 = corr_matrix.columns[indices[0][idx]]\n",
    "    col2 = corr_matrix.columns[indices[1][idx]]\n",
    "    high_corr.append(col1)\n",
    "    count+=1\n",
    "    #print(f\"{col1} and {col2}\")\n",
    "#print(count)\n",
    "\n",
    "unique_vals = set(high_corr)\n",
    "train_imputed = train_imputed.drop(unique_vals, axis = 1)\n",
    "\n",
    "test_col = train_imputed.drop('y', axis = 1)\n",
    "test_imputed = test_imputed[test_col.columns]\n",
    "\n",
    "corr_matrix = train_imputed.corr().abs()\n",
    "\n",
    "corr_y = train_imputed.corrwith(train_imputed['y'])\n",
    "\n",
    "low_corr_cols = corr_y[corr_y < 0.01].index.tolist()\n",
    "\n",
    "train_imputed = train_imputed.drop(low_corr_cols, axis = 1)\n",
    "test_col = train_imputed.drop('y', axis = 1)\n",
    "test_imputed = test_imputed[test_col.columns]\n",
    "\n",
    "X = train_imputed.drop('y', axis = 1)\n",
    "y = train_imputed.y\n",
    "\n",
    "X_test = test_imputed\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "pca = PCA(n_components = 0.99)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "X_train_pca = pca.transform(X_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb768a",
   "metadata": {},
   "source": [
    "### Creating a FFNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b29aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train_pca.shape[1],))) # input\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(500, activation='relu', kernel_initializer='he_normal')) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(200, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(20, activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5faafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc32f189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleywitarsa/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "49/49 [==============================] - 4s 72ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 3s 56ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 3s 60ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 3s 59ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 7.6285 - val_loss: 7.6468\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 7.6285 - val_loss: 7.6468\n"
     ]
    }
   ],
   "source": [
    "early = EarlyStopping('val_loss', patience=10)\n",
    "set_random_seed(0)\n",
    "history = model.fit(X_train_pca, y, epochs=100, validation_split=0.1, callbacks=early, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e776383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/138 [=>............................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleywitarsa/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = pd.DataFrame()\n",
    "pred['id'] = test['id']\n",
    "pred['y'] = model.predict(X_test_pca)\n",
    "pred = pred.set_index(['id'])\n",
    "pred.to_csv('Witarsa_Ashley_regression.csv') # 13ish RMSE so shit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e8391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
